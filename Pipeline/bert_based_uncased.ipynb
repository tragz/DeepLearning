{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f0daa1",
   "metadata": {},
   "source": [
    "# Bert Based Uncased  - Unmask \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a0024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# https://huggingface.co/google-bert/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ffa1b8",
   "metadata": {},
   "source": [
    "### Questions\n",
    "#### 1. where is the pretrained model artefacts stored on pipeline()\n",
    "#### 2. expalin the files\n",
    "        model.safetensors\n",
    "        tokenizer_config.json\n",
    "        tokenizer.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0882048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08cc262",
   "metadata": {},
   "source": [
    "# bert-base-uncased\n",
    "    1. BERT model trained on english language using MLM (Masked Language Model) and NSP (Next Sentence Prediction)\n",
    "    2. 110M parameter model\n",
    "    3. The BERT model was pretrained on BookCorpus, a dataset consisting of 11,038 unpublished books and English Wikipedia (excluding lists, tables and headers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0433e6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0138d5f3565c43f79948c749d5749cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689920dd3c524751b22da2cf17066d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2a6a789e9149eebf279c3bcb63174f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8891dd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.10731122642755508,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello i'm a fashion model.\"},\n",
       " {'score': 0.08774475753307343,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': \"hello i'm a role model.\"},\n",
       " {'score': 0.05338412895798683,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"hello i'm a new model.\"},\n",
       " {'score': 0.04667225480079651,\n",
       "  'token': 3565,\n",
       "  'token_str': 'super',\n",
       "  'sequence': \"hello i'm a super model.\"},\n",
       " {'score': 0.027095898985862732,\n",
       "  'token': 2986,\n",
       "  'token_str': 'fine',\n",
       "  'sequence': \"hello i'm a fine model.\"}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Hello I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f77e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.safetensors\n",
    "# toenizer_config.json\n",
    "# tokenizer.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3611d9",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14eb7c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " encoded_input : {'input_ids': tensor([[ 101, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      " model output : BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1386,  0.1583, -0.2967,  ..., -0.2709, -0.2844,  0.4581],\n",
      "         [ 0.5364, -0.2327,  0.1754,  ...,  0.5540,  0.4981, -0.0024],\n",
      "         [ 0.3002, -0.3475,  0.1208,  ..., -0.4562,  0.3288,  0.8773],\n",
      "         ...,\n",
      "         [ 0.3799,  0.1203,  0.8283,  ..., -0.8624, -0.5957,  0.0471],\n",
      "         [-0.0252, -0.7177, -0.6950,  ...,  0.0757, -0.6668, -0.3401],\n",
      "         [ 0.7535,  0.2391,  0.0717,  ...,  0.2467, -0.6458, -0.3213]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9377, -0.5043, -0.9799,  0.9030,  0.9329, -0.2438,  0.8926,  0.2288,\n",
      "         -0.9531, -1.0000, -0.8862,  0.9906,  0.9855,  0.7155,  0.9455, -0.8645,\n",
      "         -0.6035, -0.6666,  0.3020, -0.1587,  0.7455,  1.0000, -0.4022,  0.4261,\n",
      "          0.6151,  0.9996, -0.8773,  0.9594,  0.9585,  0.6950, -0.6718,  0.3325,\n",
      "         -0.9954, -0.2268, -0.9658, -0.9951,  0.6127, -0.7670,  0.0873,  0.0824,\n",
      "         -0.9518,  0.4713,  1.0000,  0.3299,  0.7583, -0.2670, -1.0000,  0.3166,\n",
      "         -0.9364,  0.9910,  0.9719,  0.9893,  0.2190,  0.6048,  0.5849, -0.4123,\n",
      "         -0.0063,  0.1719, -0.3988, -0.6190, -0.6603,  0.5069, -0.9757, -0.9039,\n",
      "          0.9926,  0.9323, -0.3687, -0.4869, -0.3143,  0.0499,  0.9129,  0.3396,\n",
      "         -0.1879, -0.9235,  0.8675,  0.3228, -0.6406,  1.0000, -0.7989, -0.9931,\n",
      "          0.9629,  0.9124,  0.4827, -0.7276,  0.5996, -1.0000,  0.7548, -0.1600,\n",
      "         -0.9941,  0.3386,  0.8394, -0.4158,  0.2943,  0.6111, -0.5745, -0.7185,\n",
      "         -0.4768, -0.9681, -0.4327, -0.6732,  0.1248, -0.2093, -0.5882, -0.4186,\n",
      "          0.5447, -0.6125, -0.6138,  0.4712,  0.4779,  0.7633,  0.3974, -0.4148,\n",
      "          0.7063, -0.9680,  0.7389, -0.4270, -0.9948, -0.6019, -0.9950,  0.7459,\n",
      "         -0.6343, -0.2753,  0.9522, -0.5724,  0.6218, -0.1295, -0.9905, -1.0000,\n",
      "         -0.8710, -0.7506, -0.5008, -0.4827, -0.9872, -0.9847,  0.7214,  0.9694,\n",
      "          0.3013,  1.0000, -0.4427,  0.9699, -0.5431, -0.8189,  0.9180, -0.5132,\n",
      "          0.9026,  0.5274, -0.5940,  0.2928, -0.6933,  0.7179, -0.9318, -0.2776,\n",
      "         -0.9160, -0.9457, -0.3287,  0.9556, -0.7927, -0.9860, -0.1904, -0.2760,\n",
      "         -0.6062,  0.9005,  0.9266,  0.4353, -0.6858,  0.4720,  0.2851,  0.7685,\n",
      "         -0.8647, -0.5626,  0.5127, -0.5468, -0.9490, -0.9907, -0.5809,  0.7146,\n",
      "          0.9948,  0.7981,  0.3463,  0.9349, -0.4238,  0.9333, -0.9754,  0.9936,\n",
      "         -0.2597,  0.4665, -0.5400,  0.4947, -0.8723,  0.0034,  0.8378, -0.9134,\n",
      "         -0.8432, -0.2516, -0.5177, -0.4687, -0.9491,  0.5691, -0.4856, -0.4857,\n",
      "         -0.2245,  0.9609,  0.9823,  0.7496,  0.6256,  0.8552, -0.9073, -0.5802,\n",
      "          0.2874,  0.3017,  0.3016,  0.9974, -0.8503, -0.2108, -0.9261, -0.9907,\n",
      "         -0.0252, -0.9488, -0.3972, -0.8097,  0.8707, -0.7512,  0.8107,  0.5488,\n",
      "         -0.9830, -0.8569,  0.4852, -0.6156,  0.4846, -0.2893,  0.9647,  0.9858,\n",
      "         -0.7064,  0.7120,  0.9593, -0.9590, -0.8708,  0.7893, -0.3561,  0.8603,\n",
      "         -0.7243,  0.9882,  0.9876,  0.9282, -0.9547, -0.8329, -0.7994, -0.8398,\n",
      "         -0.2333,  0.2315,  0.9712,  0.6055,  0.6388,  0.2429, -0.7884,  0.9981,\n",
      "         -0.9448, -0.9804, -0.8184, -0.3534, -0.9951,  0.9729,  0.4165,  0.8094,\n",
      "         -0.6227, -0.8183, -0.9817,  0.8532,  0.1242,  0.9826, -0.6376, -0.9450,\n",
      "         -0.8094, -0.9748,  0.0412, -0.3097, -0.8153, -0.0306, -0.9255,  0.5677,\n",
      "          0.6217,  0.6652, -0.9682,  0.9997,  1.0000,  0.9826,  0.9013,  0.8950,\n",
      "         -1.0000, -0.8081,  1.0000, -0.9995, -1.0000, -0.9361, -0.8200,  0.4755,\n",
      "         -1.0000, -0.2698, -0.0111, -0.9297,  0.8492,  0.9879,  0.9950, -1.0000,\n",
      "          0.8653,  0.9513, -0.5679,  0.9966, -0.6713,  0.9815,  0.6008,  0.7414,\n",
      "         -0.3265,  0.5574, -0.9801, -0.8956, -0.8082, -0.9267,  0.9999,  0.2542,\n",
      "         -0.7970, -0.8854,  0.7831, -0.1391, -0.0060, -0.9786, -0.4503,  0.8895,\n",
      "          0.9021,  0.3021,  0.2650, -0.5750,  0.5099,  0.1216,  0.1170,  0.6484,\n",
      "         -0.9505, -0.3889, -0.6938,  0.2508, -0.7526, -0.9831,  0.9646, -0.2742,\n",
      "          0.9865,  1.0000,  0.3756, -0.9045,  0.8847,  0.4860, -0.5515,  1.0000,\n",
      "          0.9092, -0.9904, -0.4959,  0.7900, -0.7156, -0.8280,  0.9999, -0.4197,\n",
      "         -0.9282, -0.7733,  0.9945, -0.9956,  0.9998, -0.8985, -0.9838,  0.9735,\n",
      "          0.9655, -0.8103, -0.8325,  0.1020, -0.6722,  0.4561, -0.9412,  0.8396,\n",
      "          0.6979, -0.1201,  0.9288, -0.8345, -0.6312,  0.4356, -0.8901, -0.4565,\n",
      "          0.9874,  0.5709, -0.2111, -0.0206, -0.4182, -0.9116, -0.9781,  0.8246,\n",
      "          1.0000, -0.4229,  0.9489, -0.5226, -0.0986,  0.2202,  0.7459,  0.7152,\n",
      "         -0.3528, -0.8800,  0.9299, -0.9716, -0.9949,  0.7278,  0.2206, -0.4944,\n",
      "          1.0000,  0.6285,  0.3795,  0.7228,  0.9993,  0.0301,  0.5936,  0.9816,\n",
      "          0.9914, -0.3465,  0.5882,  0.8365, -0.9824, -0.4488, -0.7612,  0.1331,\n",
      "         -0.9479, -0.0559, -0.9697,  0.9846,  0.9960,  0.5818,  0.3121,  0.8577,\n",
      "          1.0000, -0.9274,  0.6693, -0.1365,  0.8035, -1.0000, -0.8057, -0.4504,\n",
      "         -0.1711, -0.9512, -0.5899,  0.3991, -0.9754,  0.9563,  0.8806, -0.9937,\n",
      "         -0.9923, -0.4979,  0.8853,  0.1439, -0.9994, -0.8986, -0.6272,  0.8385,\n",
      "         -0.3239, -0.9470, -0.7009, -0.4768,  0.5742, -0.2216,  0.5665,  0.9667,\n",
      "          0.7935, -0.9401, -0.6746, -0.1753, -0.9163,  0.9409, -0.8701, -0.9894,\n",
      "         -0.2514,  1.0000, -0.4087,  0.9385,  0.6050,  0.8219, -0.2712,  0.3326,\n",
      "          0.9827,  0.3613, -0.8314, -0.9850, -0.2861, -0.5398,  0.8254,  0.8414,\n",
      "          0.7590,  0.9412,  0.9627,  0.2765, -0.0737,  0.0399,  0.9998, -0.3095,\n",
      "         -0.1933, -0.4689, -0.2511, -0.4629, -0.2914,  1.0000,  0.3963,  0.7777,\n",
      "         -0.9950, -0.9808, -0.9303,  1.0000,  0.8822, -0.6848,  0.8124,  0.6242,\n",
      "         -0.2551,  0.8266, -0.2791, -0.3167,  0.2294,  0.1682,  0.9627, -0.6738,\n",
      "         -0.9904, -0.7910,  0.7099, -0.9770,  1.0000, -0.7030, -0.3960, -0.5981,\n",
      "         -0.6683, -0.2727, -0.0183, -0.9882, -0.3841,  0.5605,  0.9745,  0.3505,\n",
      "         -0.4898, -0.9298,  0.9578,  0.9533, -0.9859, -0.9597,  0.9777, -0.9784,\n",
      "          0.7550,  1.0000,  0.3446,  0.6786,  0.3947, -0.5349,  0.5541, -0.6754,\n",
      "          0.8078, -0.9595, -0.4484, -0.3901,  0.3983, -0.1319, -0.2896,  0.7860,\n",
      "          0.3500, -0.5530, -0.7294, -0.2361,  0.4663,  0.9332, -0.3048, -0.1916,\n",
      "          0.2318, -0.3230, -0.9323, -0.4672, -0.6315, -1.0000,  0.8068, -1.0000,\n",
      "          0.8035,  0.4066, -0.3700,  0.8760,  0.7829,  0.8298, -0.8628, -0.9795,\n",
      "          0.1322,  0.8529, -0.5029, -0.9057, -0.6918,  0.5017, -0.2052,  0.1564,\n",
      "         -0.7397,  0.8156, -0.3414,  1.0000,  0.2659, -0.8292, -0.9821,  0.2491,\n",
      "         -0.3009,  1.0000, -0.8952, -0.9832,  0.3330, -0.9180, -0.8493,  0.5868,\n",
      "          0.1653, -0.8522, -0.9961,  0.9220,  0.8661, -0.6477,  0.7927, -0.3991,\n",
      "         -0.7691,  0.1512,  0.9868,  0.9924,  0.7317,  0.9083, -0.1226, -0.5258,\n",
      "          0.9840,  0.4009, -0.0436,  0.1361,  1.0000,  0.4004, -0.9497, -0.1309,\n",
      "         -0.9788, -0.3522, -0.9551,  0.3755,  0.3099,  0.9195, -0.4460,  0.9738,\n",
      "         -0.9714,  0.1901, -0.8894, -0.7863,  0.4757, -0.9463, -0.9892, -0.9938,\n",
      "          0.8142, -0.4077, -0.1895,  0.2102,  0.1715,  0.6322,  0.5566, -1.0000,\n",
      "          0.9642,  0.6150,  0.9768,  0.9768,  0.9115,  0.8108,  0.3251, -0.9920,\n",
      "         -0.9910, -0.5438, -0.3567,  0.7960,  0.7648,  0.8900,  0.6470, -0.4875,\n",
      "         -0.4792, -0.7756, -0.8423, -0.9972,  0.5961, -0.8679, -0.9678,  0.9718,\n",
      "         -0.3461, -0.1534, -0.2139, -0.9586,  0.9321,  0.7627,  0.4636,  0.0862,\n",
      "          0.5071,  0.9170,  0.9597,  0.9882, -0.9231,  0.8555, -0.9196,  0.6712,\n",
      "          0.9381, -0.9606,  0.2335,  0.8301, -0.5560,  0.3696, -0.4752, -0.9740,\n",
      "          0.8174, -0.4268,  0.7773, -0.4798,  0.0639, -0.4718, -0.2607, -0.7624,\n",
      "         -0.8742,  0.6576,  0.6207,  0.9219,  0.9360, -0.0496, -0.8942, -0.3701,\n",
      "         -0.8944, -0.9526,  0.9536, -0.0851, -0.2961,  0.9031,  0.1321,  0.9324,\n",
      "          0.4289, -0.4989, -0.4174, -0.7639,  0.8887, -0.7894, -0.7639, -0.7093,\n",
      "          0.8105,  0.3595,  1.0000, -0.9188, -0.9878, -0.8268, -0.6012,  0.4992,\n",
      "         -0.7880, -1.0000,  0.3609, -0.8314,  0.8524, -0.9398,  0.9500, -0.9339,\n",
      "         -0.9851, -0.3495,  0.8436,  0.9375, -0.5159, -0.8989,  0.5196, -0.8797,\n",
      "          0.9979,  0.8753, -0.8277, -0.0012,  0.6013, -0.9184, -0.7398,  0.9228]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "print(f\" encoded_input : {encoded_input}\")\n",
    "output = model(**encoded_input)\n",
    "print(f\" model output : {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5b92f6",
   "metadata": {},
   "source": [
    "### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37a8774b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " encoded_input : {'input_ids': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=\n",
      "array([[ 101, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,\n",
      "         102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n",
      " model output : TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(1, 12, 768), dtype=float32, numpy=\n",
      "array([[[ 0.13862716,  0.15826902, -0.29666442, ..., -0.27084988,\n",
      "         -0.2843625 ,  0.45808458],\n",
      "        [ 0.53636444, -0.23269658,  0.17541921, ...,  0.55402625,\n",
      "          0.49807212, -0.00240695],\n",
      "        [ 0.3002378 , -0.3475114 ,  0.12084387, ..., -0.45624796,\n",
      "          0.32880175,  0.87728184],\n",
      "        ...,\n",
      "        [ 0.3798598 ,  0.12028816,  0.82829314, ..., -0.86237156,\n",
      "         -0.59569657,  0.04711513],\n",
      "        [-0.0252414 , -0.71767473, -0.69504815, ...,  0.07574296,\n",
      "         -0.66678077, -0.3400748 ],\n",
      "        [ 0.7535388 ,  0.23910934,  0.07174402, ...,  0.24671513,\n",
      "         -0.64580595, -0.3212978 ]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
      "array([[-0.9376787 , -0.5042589 , -0.9798931 ,  0.9030441 ,  0.93293256,\n",
      "        -0.24377489,  0.89257544,  0.22880599, -0.9531209 , -0.99999535,\n",
      "        -0.88623023,  0.9905573 ,  0.98552006,  0.71552855,  0.9454763 ,\n",
      "        -0.864485  , -0.60352355, -0.6665585 ,  0.30200136, -0.15873352,\n",
      "         0.7455273 ,  0.99999976, -0.40218848,  0.42608023,  0.61509   ,\n",
      "         0.99962306, -0.8773362 ,  0.9593896 ,  0.9585287 ,  0.6950152 ,\n",
      "        -0.6718386 ,  0.3325089 , -0.9953591 , -0.2267549 , -0.9657978 ,\n",
      "        -0.9951097 ,  0.61270165, -0.7669507 ,  0.08734461,  0.08236415,\n",
      "        -0.9518444 ,  0.4712975 ,  0.9999978 ,  0.3298951 ,  0.75830996,\n",
      "        -0.26704812, -0.99999976,  0.3166447 , -0.9364275 ,  0.9910323 ,\n",
      "         0.9719467 ,  0.9892897 ,  0.21901836,  0.60477006,  0.58489966,\n",
      "        -0.4122716 , -0.00629409,  0.17190626, -0.39875737, -0.618993  ,\n",
      "        -0.66031545,  0.50686777, -0.9756918 , -0.903931  ,  0.9926242 ,\n",
      "         0.9322653 , -0.3687319 , -0.4869069 , -0.314323  ,  0.04989544,\n",
      "         0.9129026 ,  0.33961445, -0.18794715, -0.9234626 ,  0.86747605,\n",
      "         0.32275364, -0.640608  ,  0.99999976, -0.7988528 , -0.9930687 ,\n",
      "         0.962933  ,  0.9124064 ,  0.48271638, -0.7275582 ,  0.5996146 ,\n",
      "        -0.99999976,  0.7548478 , -0.15997005, -0.994149  ,  0.33858255,\n",
      "         0.8394348 , -0.4157738 ,  0.29430988,  0.61109644, -0.57447684,\n",
      "        -0.7184508 , -0.47684044, -0.96814406, -0.43267035, -0.6732335 ,\n",
      "         0.12483019, -0.20933405, -0.5881843 , -0.4186068 ,  0.5447091 ,\n",
      "        -0.6125471 , -0.6138068 ,  0.4712149 ,  0.47791407,  0.76332897,\n",
      "         0.39740175, -0.41479257,  0.7063263 , -0.9680179 ,  0.73894525,\n",
      "        -0.4269572 , -0.9947575 , -0.6018677 , -0.9950457 ,  0.74590683,\n",
      "        -0.634281  , -0.27531835,  0.95222396, -0.5724269 ,  0.6217952 ,\n",
      "        -0.12949015, -0.9905181 , -0.99999976, -0.8709735 , -0.75060683,\n",
      "        -0.5008357 , -0.48268548, -0.98716307, -0.9847019 ,  0.72136205,\n",
      "         0.9694465 ,  0.3012809 ,  0.99999064, -0.4426685 ,  0.9698506 ,\n",
      "        -0.54311854, -0.8188719 ,  0.9180296 , -0.5131957 ,  0.9025569 ,\n",
      "         0.5273865 , -0.5939677 ,  0.2927999 , -0.6932561 ,  0.71791214,\n",
      "        -0.9318367 , -0.27759165, -0.9160482 , -0.9456747 , -0.3286885 ,\n",
      "         0.95555574, -0.7927074 , -0.9860028 , -0.19044137, -0.27600542,\n",
      "        -0.6061539 ,  0.9005308 ,  0.9266374 ,  0.43529776, -0.68583065,\n",
      "         0.47203988,  0.28506842,  0.7684513 , -0.86466587, -0.56257737,\n",
      "         0.5126705 , -0.5468342 , -0.94900864, -0.99071175, -0.5809061 ,\n",
      "         0.7146273 ,  0.9948339 ,  0.79809046,  0.3462591 ,  0.9348572 ,\n",
      "        -0.42384446,  0.93327016, -0.9754466 ,  0.99358267, -0.25965124,\n",
      "         0.46646726, -0.53999937,  0.49472576, -0.8722778 ,  0.00338863,\n",
      "         0.83776444, -0.913425  , -0.8431693 , -0.25158235, -0.5176902 ,\n",
      "        -0.46870983, -0.9490976 ,  0.5691279 , -0.48558098, -0.4856519 ,\n",
      "        -0.22445986,  0.9609392 ,  0.98228943,  0.7495636 ,  0.6255511 ,\n",
      "         0.85518974, -0.9073243 , -0.5802432 ,  0.28742275,  0.3017121 ,\n",
      "         0.30159423,  0.99737537, -0.85030496, -0.21080582, -0.9260726 ,\n",
      "        -0.990708  , -0.02516793, -0.9488479 , -0.3971861 , -0.80972636,\n",
      "         0.87068224, -0.75122845,  0.8106708 ,  0.54876286, -0.98298633,\n",
      "        -0.8569215 ,  0.48523533, -0.61555696,  0.48461306, -0.28931558,\n",
      "         0.96470964,  0.985797  , -0.70642924,  0.7120397 ,  0.95934504,\n",
      "        -0.9589811 , -0.87075084,  0.78927684, -0.35606402,  0.86029977,\n",
      "        -0.72429246,  0.9881865 ,  0.9875786 ,  0.9282262 , -0.95474756,\n",
      "        -0.8328892 , -0.7993498 , -0.83976924, -0.23329651,  0.23149188,\n",
      "         0.9711686 ,  0.60545284,  0.6388194 ,  0.2428675 , -0.78839785,\n",
      "         0.9981302 , -0.94476086, -0.9803667 , -0.81843835, -0.3533669 ,\n",
      "        -0.9950912 ,  0.97287905,  0.41646662,  0.809369  , -0.6227092 ,\n",
      "        -0.8183279 , -0.98167413,  0.8531912 ,  0.12420855,  0.9826024 ,\n",
      "        -0.63760746, -0.94500613, -0.8093605 , -0.97478217,  0.04118001,\n",
      "        -0.30971003, -0.8153307 , -0.03058985, -0.9255174 ,  0.5676857 ,\n",
      "         0.62166023,  0.6651732 , -0.9682159 ,  0.99972993,  0.99999976,\n",
      "         0.9825574 ,  0.9013465 ,  0.8950183 , -0.9999985 , -0.8081251 ,\n",
      "         0.9999988 , -0.9995222 , -0.99999976, -0.9361453 , -0.82000816,\n",
      "         0.47551483, -0.99999976, -0.269762  , -0.01114204, -0.92966133,\n",
      "         0.84915453,  0.9879218 ,  0.9950282 , -0.99999976,  0.8652959 ,\n",
      "         0.9512623 , -0.5678967 ,  0.9965562 , -0.67130387,  0.9814816 ,\n",
      "         0.6007992 ,  0.7414179 , -0.3265391 ,  0.55741   , -0.9800917 ,\n",
      "        -0.89560366, -0.80820966, -0.9266759 ,  0.9999364 ,  0.25422582,\n",
      "        -0.79697573, -0.88540417,  0.78310853, -0.13913631, -0.00604189,\n",
      "        -0.9786411 , -0.45033976,  0.88950574,  0.9020898 ,  0.3021423 ,\n",
      "         0.2650315 , -0.5750342 ,  0.5098624 ,  0.12155071,  0.1170202 ,\n",
      "         0.64841014, -0.95048785, -0.3888617 , -0.69375086,  0.2507663 ,\n",
      "        -0.75262487, -0.983106  ,  0.9646209 , -0.27421284,  0.98648345,\n",
      "         0.99999976,  0.37562212, -0.9045104 ,  0.8846976 ,  0.4860112 ,\n",
      "        -0.55146456,  0.99999976,  0.90921575, -0.9904048 , -0.49585935,\n",
      "         0.79001343, -0.7155994 , -0.8280249 ,  0.99985814, -0.4197408 ,\n",
      "        -0.9281557 , -0.7732698 ,  0.9944566 , -0.99556184,  0.9997706 ,\n",
      "        -0.89851373, -0.98384994,  0.9734995 ,  0.96547353, -0.81029963,\n",
      "        -0.8325335 ,  0.10202586, -0.6722141 ,  0.45613533, -0.9412213 ,\n",
      "         0.8395838 ,  0.6978767 , -0.12014562,  0.9287757 , -0.834504  ,\n",
      "        -0.6312201 ,  0.4355716 , -0.8900794 , -0.45648625,  0.9873616 ,\n",
      "         0.57085353, -0.2110516 , -0.02060684, -0.41823655, -0.9115845 ,\n",
      "        -0.97806305,  0.8245926 ,  0.99999976, -0.42286906,  0.9489128 ,\n",
      "        -0.52259123, -0.09856702,  0.22024457,  0.7459151 ,  0.7152115 ,\n",
      "        -0.3527778 , -0.8799705 ,  0.9298511 , -0.9716049 , -0.99490005,\n",
      "         0.7277599 ,  0.22061615, -0.49437487,  0.99999976,  0.62849957,\n",
      "         0.37947997,  0.7227851 ,  0.9993162 ,  0.03006973,  0.59361887,\n",
      "         0.98155195,  0.9914458 , -0.34654376,  0.58822066,  0.8365398 ,\n",
      "        -0.98242056, -0.44884238, -0.76117074,  0.13310789, -0.9479299 ,\n",
      "        -0.05588   , -0.96974975,  0.98457885,  0.9960217 ,  0.5818412 ,\n",
      "         0.31210375,  0.85770607,  0.99999976, -0.92739046,  0.66934896,\n",
      "        -0.13647212,  0.80350417, -0.9999917 , -0.80565137, -0.45044866,\n",
      "        -0.17113768, -0.9512213 , -0.589885  ,  0.39912355, -0.9754495 ,\n",
      "         0.9563166 ,  0.88056123, -0.9937363 , -0.9922803 , -0.49792978,\n",
      "         0.88532585,  0.14390929, -0.9993915 , -0.8985792 , -0.627229  ,\n",
      "         0.8385113 , -0.3238534 , -0.9470191 , -0.7008788 , -0.47676116,\n",
      "         0.57417893, -0.22156946,  0.56645584,  0.9666835 ,  0.7934852 ,\n",
      "        -0.9401055 , -0.6745938 , -0.17533818, -0.91634184,  0.94093406,\n",
      "        -0.8701091 , -0.9893604 , -0.25140816,  0.99999976, -0.40869674,\n",
      "         0.93852764,  0.60501206,  0.8218856 , -0.2712239 ,  0.33262107,\n",
      "         0.98272383,  0.36131942, -0.831421  , -0.98497045, -0.28606436,\n",
      "        -0.5398209 ,  0.8254337 ,  0.8414237 ,  0.7590129 ,  0.9412288 ,\n",
      "         0.9627104 ,  0.27651   , -0.073725  ,  0.03992773,  0.9998473 ,\n",
      "        -0.30951753, -0.19327542, -0.46890196, -0.25110948, -0.462913  ,\n",
      "        -0.291374  ,  0.99999976,  0.39625415,  0.7777107 , -0.9949603 ,\n",
      "        -0.98075765, -0.930253  ,  0.99999976,  0.88222456, -0.6848308 ,\n",
      "         0.81237376,  0.6241763 , -0.25508168,  0.8266011 , -0.27906552,\n",
      "        -0.31672698,  0.22944506,  0.16818143,  0.9627002 , -0.6737689 ,\n",
      "        -0.9903569 , -0.7910485 ,  0.70993763, -0.9769668 ,  0.9999993 ,\n",
      "        -0.7029679 , -0.39604852, -0.5981425 , -0.6682932 , -0.27273366,\n",
      "        -0.01829579, -0.9881754 , -0.3841481 ,  0.56053245,  0.97445375,\n",
      "         0.35048926, -0.48977154, -0.929834  ,  0.95783514,  0.953261  ,\n",
      "        -0.98588705, -0.9597454 ,  0.9777033 , -0.978429  ,  0.7550497 ,\n",
      "         0.99999976,  0.3445876 ,  0.6786016 ,  0.39467096, -0.53489065,\n",
      "         0.55405414, -0.67538315,  0.8077888 , -0.9594636 , -0.4484237 ,\n",
      "        -0.3900548 ,  0.3983124 , -0.13191757, -0.2895931 ,  0.78603196,\n",
      "         0.34999257, -0.55303085, -0.72944576, -0.23607792,  0.46634495,\n",
      "         0.93319285, -0.30481067, -0.19163463,  0.23183015, -0.323048  ,\n",
      "        -0.93234104, -0.4672352 , -0.6315391 , -0.99999976,  0.8067948 ,\n",
      "        -0.99999976,  0.8035265 ,  0.40656883, -0.36996412,  0.8760369 ,\n",
      "         0.7829031 ,  0.8298428 , -0.8628252 , -0.9794617 ,  0.13217969,\n",
      "         0.85292894, -0.50289536, -0.90573984, -0.69177604,  0.5016609 ,\n",
      "        -0.20521925,  0.15640728, -0.7397342 ,  0.8155632 , -0.34136406,\n",
      "         0.99999976,  0.2658981 , -0.8292071 , -0.98211795,  0.24909703,\n",
      "        -0.30092302,  0.99999976, -0.89523524, -0.9831534 ,  0.33299068,\n",
      "        -0.9179502 , -0.84932905,  0.58675593,  0.16526444, -0.85224754,\n",
      "        -0.9960892 ,  0.92204565,  0.8660802 , -0.6476969 ,  0.7927419 ,\n",
      "        -0.3990841 , -0.76908255,  0.15115342,  0.9868104 ,  0.9924342 ,\n",
      "         0.73167485,  0.9082755 , -0.12264884, -0.5258374 ,  0.9840351 ,\n",
      "         0.4008642 , -0.04361057,  0.1360867 ,  0.99999976,  0.400372  ,\n",
      "        -0.9497184 , -0.13093893, -0.97876024, -0.35216945, -0.9551132 ,\n",
      "         0.37547466,  0.30993962,  0.919471  , -0.4460048 ,  0.97381103,\n",
      "        -0.9713665 ,  0.1900935 , -0.8894485 , -0.7863345 ,  0.47566864,\n",
      "        -0.94628006, -0.98922896, -0.99379843,  0.8141797 , -0.40769193,\n",
      "        -0.18949994,  0.21021213,  0.1715005 ,  0.63221514,  0.55656344,\n",
      "        -0.99999976,  0.9642159 ,  0.61497796,  0.9767502 ,  0.97680116,\n",
      "         0.91147447,  0.81081516,  0.32505706, -0.9919877 , -0.991035  ,\n",
      "        -0.54379773, -0.3567472 ,  0.79595333,  0.76478755,  0.8900012 ,\n",
      "         0.64696026, -0.48747814, -0.47918597, -0.7755678 , -0.8422663 ,\n",
      "        -0.9971619 ,  0.59613276, -0.8679444 , -0.967766  ,  0.97183484,\n",
      "        -0.34611037, -0.15342851, -0.21388368, -0.95864207,  0.9321083 ,\n",
      "         0.7627048 ,  0.46363863,  0.08617745,  0.5070988 ,  0.9170014 ,\n",
      "         0.9596648 ,  0.9881745 , -0.92305714,  0.85545844, -0.91963255,\n",
      "         0.6712208 ,  0.93809915, -0.9606302 ,  0.23346205,  0.8300924 ,\n",
      "        -0.55601096,  0.36960736, -0.47518617, -0.97400516,  0.81737524,\n",
      "        -0.4267747 ,  0.77727896, -0.47978646,  0.06386235, -0.47184733,\n",
      "        -0.26067346, -0.762368  , -0.87422585,  0.6576244 ,  0.62072194,\n",
      "         0.9219023 ,  0.9359768 , -0.04963606, -0.8942282 , -0.37006134,\n",
      "        -0.8943976 , -0.9525816 ,  0.95360756, -0.0850936 , -0.2960982 ,\n",
      "         0.9030917 ,  0.13211574,  0.9323627 ,  0.42885348, -0.4989079 ,\n",
      "        -0.4174366 , -0.7638584 ,  0.8886791 , -0.7894223 , -0.76387584,\n",
      "        -0.7092896 ,  0.8104626 ,  0.35951042,  0.99999976, -0.9188115 ,\n",
      "        -0.9877863 , -0.82680064, -0.6011908 ,  0.49917856, -0.78802043,\n",
      "        -0.99999976,  0.36094287, -0.831356  ,  0.85240614, -0.9397851 ,\n",
      "         0.94995785, -0.93385285, -0.98512524, -0.34948173,  0.843627  ,\n",
      "         0.9374619 , -0.5158688 , -0.8989186 ,  0.5195584 , -0.87971115,\n",
      "         0.9979246 ,  0.87525624, -0.8276661 , -0.00118575,  0.6012698 ,\n",
      "        -0.918448  , -0.7397866 ,  0.9227984 ]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='tf')\n",
    "print(f\" encoded_input : {encoded_input}\")\n",
    "output = model(**encoded_input)\n",
    "print(f\" model output : {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93348b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
